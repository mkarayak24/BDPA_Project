{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PFqXhstjgwFl"
      },
      "outputs": [],
      "source": [
        "# PySpark and others\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, year, stddev, mean, lit, lead, min as spark_min, max as spark_max\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.sql import Window\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tJMrTj7fivIa"
      },
      "outputs": [],
      "source": [
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Stock Data Analysis\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hwhFDkC1a4mN"
      },
      "outputs": [],
      "source": [
        "all_df = spark.read.csv(\"nasdaq100.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycUS0YsKbS_1",
        "outputId": "b6a7b07e-8283-4a3f-c88a-9faf873def4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+-------+-------+-------+-------+\n",
            "|ticker|      date|   open|   high|    low|  close|\n",
            "+------+----------+-------+-------+-------+-------+\n",
            "|  CSCO|2011-01-03|14.5212| 14.644|14.4741|14.5516|\n",
            "|  CSCO|2011-01-04|14.6116|14.6282|14.4868|14.5722|\n",
            "|  CSCO|2011-01-05|14.6116|14.8089|14.5782| 14.751|\n",
            "|  CSCO|2011-01-06|14.8423|14.8806|14.7422|14.8737|\n",
            "|  CSCO|2011-01-07|14.8089| 14.913|14.7932|14.8904|\n",
            "+------+----------+-------+-------+-------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "all_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzhDdb-AkJnB",
        "outputId": "a90ae6e3-b2aa-48a6-bd48-43469f10b3ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|ticker|\n",
            "+------+\n",
            "|  CSCO|\n",
            "|  MCHP|\n",
            "|   ADI|\n",
            "|  GILD|\n",
            "|  MNST|\n",
            "|  INTC|\n",
            "|   MDB|\n",
            "|  INTU|\n",
            "|  CCEP|\n",
            "|  VRTX|\n",
            "|   PDD|\n",
            "|  GEHC|\n",
            "|  COST|\n",
            "|  ISRG|\n",
            "|  ABNB|\n",
            "|   WBD|\n",
            "|  MSTR|\n",
            "|   GFS|\n",
            "|   KDP|\n",
            "|  WDAY|\n",
            "+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+-----+\n",
            "|ticker|count|\n",
            "+------+-----+\n",
            "|  CSCO| 3570|\n",
            "|  MCHP| 3570|\n",
            "|   ADI| 3570|\n",
            "|  GILD| 3570|\n",
            "|  MNST| 3570|\n",
            "|  INTC| 3570|\n",
            "|   MDB| 1859|\n",
            "|  INTU| 3570|\n",
            "|  CCEP| 3570|\n",
            "|  VRTX| 3570|\n",
            "|   PDD| 1667|\n",
            "|  GEHC|  561|\n",
            "|  COST| 3570|\n",
            "|  ISRG| 3570|\n",
            "|  ABNB| 1068|\n",
            "|   WBD| 3570|\n",
            "|  MSTR| 3570|\n",
            "|   GFS|  846|\n",
            "|   KDP| 3570|\n",
            "|  WDAY| 3121|\n",
            "+------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check distinct tickers\n",
        "all_df.select(\"ticker\").distinct().show()\n",
        "all_df.groupBy(\"ticker\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----+----+----+---+-----+\n",
            "|ticker|date|open|high|low|close|\n",
            "+------+----+----+----+---+-----+\n",
            "|     0|   0|   0|   0|  0|    0|\n",
            "+------+----+----+----+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values in the dataset\n",
        "\n",
        "from pyspark.sql.functions import sum\n",
        "\n",
        "# Check missing values for each column in the combined dataset\n",
        "all_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in all_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qwBsOFUQkPWc"
      },
      "outputs": [],
      "source": [
        "# Training set (before 2017)\n",
        "train_period = all_df.filter((col(\"date\") >= \"2011-01-01\") & (col(\"date\") <= \"2016-12-31\"))\n",
        "\n",
        "# Testing Periods Filtering\n",
        "stable_period = all_df.filter((col(\"date\") >= \"2017-01-01\") & (col(\"date\") <= \"2017-12-31\"))\n",
        "trade_war_period = all_df.filter((col(\"date\") >= \"2018-01-01\") & (col(\"date\") <= \"2019-12-31\"))\n",
        "covid_period = all_df.filter((col(\"date\") >= \"2020-02-01\") & (col(\"date\") <= \"2020-08-31\"))\n",
        "ukraine_period = all_df.filter((col(\"date\") >= \"2022-02-01\") & (col(\"date\") <= \"2022-12-31\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in stable period:\n",
            "+------+----+----+----+---+-----+\n",
            "|ticker|date|open|high|low|close|\n",
            "+------+----+----+----+---+-----+\n",
            "|     0|   0|   0|   0|  0|    0|\n",
            "+------+----+----+----+---+-----+\n",
            "\n",
            "Missing values in US-China Trade War testing period:\n",
            "+------+----+----+----+---+-----+\n",
            "|ticker|date|open|high|low|close|\n",
            "+------+----+----+----+---+-----+\n",
            "|     0|   0|   0|   0|  0|    0|\n",
            "+------+----+----+----+---+-----+\n",
            "\n",
            "Missing values in COVID-19 testing period:\n",
            "+------+----+----+----+---+-----+\n",
            "|ticker|date|open|high|low|close|\n",
            "+------+----+----+----+---+-----+\n",
            "|     0|   0|   0|   0|  0|    0|\n",
            "+------+----+----+----+---+-----+\n",
            "\n",
            "Missing values in Russia-Ukraine Conflict testing period:\n",
            "+------+----+----+----+---+-----+\n",
            "|ticker|date|open|high|low|close|\n",
            "+------+----+----+----+---+-----+\n",
            "|     0|   0|   0|   0|  0|    0|\n",
            "+------+----+----+----+---+-----+\n",
            "\n",
            "Missing values in stable period:\n",
            "+------+----+----+----+---+-----+\n",
            "|ticker|date|open|high|low|close|\n",
            "+------+----+----+----+---+-----+\n",
            "|     0|   0|   0|   0|  0|    0|\n",
            "+------+----+----+----+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# List missing values in the datasets\n",
        "\n",
        "# For stable period\n",
        "print(\"Missing values in stable period:\")\n",
        "stable_period.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in stable_period.columns]).show()\n",
        "\n",
        "# For US-China Trade War period\n",
        "print(\"Missing values in US-China Trade War testing period:\")\n",
        "trade_war_period.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in trade_war_period.columns]).show()\n",
        "\n",
        "# For COVID-19 period\n",
        "print(\"Missing values in COVID-19 testing period:\")\n",
        "covid_period.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in covid_period.columns]).show()\n",
        "\n",
        "# For Russia-Ukraine Conflict period\n",
        "print(\"Missing values in Russia-Ukraine Conflict testing period:\")\n",
        "ukraine_period.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in ukraine_period.columns]).show()\n",
        "\n",
        "# For train period\n",
        "print(\"Missing values in stable period:\")\n",
        "train_period.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in train_period.columns]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmPrKHRGQwaf",
        "outputId": "1f008abc-980c-4824-887b-50f33f9d5728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset shape: (124166, 6)\n",
            "Satbel period dataset shape: (21887, 6)\n",
            "Trade war period dataset shape: (45290, 6)\n",
            "Covid period dataset shape: (13524, 6)\n",
            "Ukraine period dataset shape: (22649, 6)\n"
          ]
        }
      ],
      "source": [
        "# Check the number of rows in each dataset\n",
        "\n",
        "pandas_df = train_period.toPandas()\n",
        "print(f\"Training dataset shape: {pandas_df.shape}\")\n",
        "\n",
        "pandas_df = stable_period.toPandas()\n",
        "print(f\"Satbel period dataset shape: {pandas_df.shape}\")\n",
        "\n",
        "pandas_df = trade_war_period.toPandas()\n",
        "print(f\"Trade war period dataset shape: {pandas_df.shape}\")\n",
        "\n",
        "pandas_df = covid_period.toPandas()\n",
        "print(f\"Covid period dataset shape: {pandas_df.shape}\")\n",
        "\n",
        "pandas_df = ukraine_period.toPandas()  \n",
        "print(f\"Ukraine period dataset shape: {pandas_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "124166"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Substep 7:\n",
        "\n",
        "# Cache the train period DataFrame\n",
        "train_period.cache()\n",
        "\n",
        "# Cache the disruption period DataFrames\n",
        "stable_period.cache()\n",
        "trade_war_period.cache()\n",
        "covid_period.cache()\n",
        "ukraine_period.cache()\n",
        "\n",
        "# Force caching by doing a small action like counting\n",
        "stable_period.count()\n",
        "trade_war_period.count()\n",
        "covid_period.count()\n",
        "ukraine_period.count()\n",
        "train_period.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Considering the features for the model, we will use the following features:  \n",
        "# - Moving averages (5 and 10 days)\n",
        "# - Volatility (5 and 10 days)\n",
        "# - Lagged values (1 day)\n",
        "# - Returns (open-close, high-low, close-lag1)\n",
        "# - Label (1 if the next day close price is higher than the current day close price, 0 otherwise)\n",
        "# - Label (regression): the percentage change in the close price from the current day to the next day\n",
        "\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import avg, stddev, lag, lead, when\n",
        "\n",
        "# Common window specifications\n",
        "window_spec_5 = Window.partitionBy(\"ticker\").orderBy(\"date\").rowsBetween(-4, 0)\n",
        "window_spec_10 = Window.partitionBy(\"ticker\").orderBy(\"date\").rowsBetween(-9, 0)\n",
        "window_spec_lag = Window.partitionBy(\"ticker\").orderBy(\"date\")\n",
        "window_spec_lead = Window.partitionBy(\"ticker\").orderBy(\"date\")\n",
        "\n",
        "# Function to add all features\n",
        "def add_features(df):\n",
        "    return df \\\n",
        "        .withColumn(\"ma_5\", avg(\"close\").over(window_spec_5)) \\\n",
        "        .withColumn(\"ma_10\", avg(\"close\").over(window_spec_10)) \\\n",
        "        .withColumn(\"volatility_5\", stddev(\"close\").over(window_spec_5)) \\\n",
        "        .withColumn(\"volatility_10\", stddev(\"close\").over(window_spec_10)) \\\n",
        "        .withColumn(\"close_lag1\", lag(\"close\", 1).over(window_spec_lag)) \\\n",
        "        .withColumn(\"open_lag1\", lag(\"open\", 1).over(window_spec_lag)) \\\n",
        "        .withColumn(\"high_lag1\", lag(\"high\", 1).over(window_spec_lag)) \\\n",
        "        .withColumn(\"low_lag1\", lag(\"low\", 1).over(window_spec_lag)) \\\n",
        "        .withColumn(\"return_open_close\", (col(\"close\") - col(\"open\")) / col(\"open\")) \\\n",
        "        .withColumn(\"return_high_low\", (col(\"high\") - col(\"low\")) / col(\"open\")) \\\n",
        "        .withColumn(\"return_close_lag1\", (col(\"close\") - col(\"close_lag1\")) / col(\"close_lag1\")) \\\n",
        "        .withColumn(\"close_lead1\", lead(\"close\", 1).over(window_spec_lead)) \\\n",
        "        .withColumn(\"label_class\", when(col(\"close_lead1\") > col(\"close\"), 1).otherwise(0)) \\\n",
        "        .withColumn(\"label_regress\", (col(\"close_lead1\") - col(\"close\")) / col(\"close\"))\n",
        "\n",
        "# Apply to training set\n",
        "train_period = add_features(train_period)\n",
        "\n",
        "# Apply to each testing set\n",
        "stable_period = add_features(stable_period)\n",
        "trade_war_period = add_features(trade_war_period)\n",
        "covid_period = add_features(covid_period)   \n",
        "ukraine_period = add_features(ukraine_period)   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building the feature set for both classification and regression tasks\n",
        "\n",
        "feature_columns = [\n",
        "    \"open\", \"high\", \"low\", \"close\",\n",
        "    \"ma_5\", \"ma_10\", \"volatility_5\", \"volatility_10\",\n",
        "    \"close_lag1\", \"open_lag1\", \"high_lag1\", \"low_lag1\",\n",
        "    \"return_open_close\", \"return_high_low\", \"return_close_lag1\"\n",
        "]\n",
        "\n",
        "# For classification task\n",
        "classification_columns = feature_columns + [\"label_class\"]\n",
        "\n",
        "# For regression task\n",
        "regression_columns = feature_columns + [\"label_regress\"]\n",
        "\n",
        "# For classification, select only these columns for the training period and disruptions periods\n",
        "train_period_class = train_period.select(classification_columns)\n",
        "stable_period_class = stable_period.select(classification_columns)\n",
        "trade_war_period_class = trade_war_period.select(classification_columns)\n",
        "covid_period_class = covid_period.select(classification_columns)\n",
        "ukraine_period_class = ukraine_period.select(classification_columns)\n",
        "\n",
        "# For regression, select only these columns for the training period and disruptions periods\n",
        "train_period_regress = train_period.select(regression_columns)\n",
        "stable_period_regress = stable_period.select(regression_columns)\n",
        "trade_war_period_regress = trade_war_period.select(regression_columns)\n",
        "covid_period_regress = covid_period.select(regression_columns)\n",
        "ukraine_period_regress = ukraine_period.select(regression_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Applying VectorAssembler to create feature vectors for both classification and regression tasks\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Define assembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=feature_columns,\n",
        "    handleInvalid=\"skip\",\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Apply the assembler to training dataset for classification\n",
        "train_period_class = assembler.transform(train_period_class)\n",
        "\n",
        "# Apply the assembler for test datasets for classification\n",
        "stable_period_class = assembler.transform(stable_period_class)\n",
        "trade_war_period_class = assembler.transform(trade_war_period_class)\n",
        "covid_period_class = assembler.transform(covid_period_class)\n",
        "ukraine_period_class = assembler.transform(ukraine_period_class)\n",
        "\n",
        "\n",
        "# Apply the assembler for regression datasets\n",
        "train_period_regress = assembler.transform(train_period_regress)\n",
        "\n",
        "# Apply the assembler for regression datasets\n",
        "stable_period_regress = assembler.transform(stable_period_regress)\n",
        "trade_war_period_regress = assembler.transform(trade_war_period_regress)\n",
        "covid_period_regress = assembler.transform(covid_period_regress)\n",
        "ukraine_period_regress = assembler.transform(ukraine_period_regress)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scaling the features using StandardScaler for both classification and regression tasks\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "scaler_model = scaler.fit(train_period_class)\n",
        "\n",
        "train_period_class_scaled = scaler_model.transform(train_period_class)\n",
        "stable_period_class_scaled = scaler_model.transform(stable_period_class)\n",
        "trade_war_period_class_scaled = scaler_model.transform(trade_war_period_class)\n",
        "covid_period_class_scaled = scaler_model.transform(covid_period_class)\n",
        "ukraine_period_class_scaled = scaler_model.transform(ukraine_period_class)\n",
        "\n",
        "train_period_regress_scaled = scaler_model.transform(train_period_regress)\n",
        "stable_period_regress_scaled = scaler_model.transform(stable_period_regress)\n",
        "trade_war_period_regress_scaled = scaler_model.transform(trade_war_period_regress)\n",
        "covid_period_regress_scaled = scaler_model.transform(covid_period_regress)\n",
        "ukraine_period_regress_scaled = scaler_model.transform(ukraine_period_regress)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove rows with missing values\n",
        "\n",
        "# for scaled dataset\n",
        "train_period_regress_scaled = train_period_regress_scaled.filter(col(\"label_regress\").cast(\"double\").isNotNull())\n",
        "stable_period_regress_scaled = stable_period_regress_scaled.filter(col(\"label_regress\").cast(\"double\").isNotNull())\n",
        "trade_war_period_regress_scaled = trade_war_period_regress_scaled.filter(col(\"label_regress\").cast(\"double\").isNotNull())\n",
        "covid_period_regress_scaled = covid_period_regress_scaled.filter(col(\"label_regress\").cast(\"double\").isNotNull())\n",
        "ukraine_period_regress_scaled = ukraine_period_regress_scaled.filter(col(\"label_regress\").cast(\"double\").isNotNull())\n",
        "\n",
        "# for unscaled dataset\n",
        "# remove rows with missing values\n",
        "train_period_regress = train_period_regress.filter(col(\"label_regress\").cast(\"double\").isNotNull())\n",
        "stable_period_regress = stable_period_regress.filter(col(\"label_regress\").cast(\"double\").isNotNull())\n",
        "trade_war_period_regress = trade_war_period_regress.filter(col(\"label_regress\").cast(\"double\").isNotNull())\n",
        "covid_period_regress = covid_period_regress.filter(col(\"label_regress\").cast(\"double\").isNotNull())\n",
        "ukraine_period_regress = ukraine_period_regress.filter(col(\"label_regress\").cast(\"double\").isNotNull())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification in 4 Ways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SCALED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training LogisticRegression...\n",
            "Stable period Accuracy: 0.5389\n",
            "Stable period F1 Score: 0.4142\n",
            "Trade War period Accuracy: 0.5336\n",
            "Trade War period F1 Score: 0.4324\n",
            "COVID period Accuracy: 0.5386\n",
            "COVID period F1 Score: 0.4814\n",
            "Ukraine period Accuracy: 0.4964\n",
            "Ukraine period F1 Score: 0.4320\n",
            "\n",
            "Training RandomForestClassifier...\n",
            "Stable period Accuracy: 0.5305\n",
            "Stable period F1 Score: 0.4803\n",
            "Trade War period Accuracy: 0.5220\n",
            "Trade War period F1 Score: 0.4834\n",
            "COVID period Accuracy: 0.5386\n",
            "COVID period F1 Score: 0.5126\n",
            "Ukraine period Accuracy: 0.4917\n",
            "Ukraine period F1 Score: 0.4601\n",
            "\n",
            "Training GBTClassifier...\n",
            "Stable period Accuracy: 0.5249\n",
            "Stable period F1 Score: 0.5026\n",
            "Trade War period Accuracy: 0.5161\n",
            "Trade War period F1 Score: 0.4967\n",
            "COVID period Accuracy: 0.5226\n",
            "COVID period F1 Score: 0.5130\n",
            "Ukraine period Accuracy: 0.4987\n",
            "Ukraine period F1 Score: 0.4840\n",
            "\n",
            "Training DecisionTreeClassifier...\n",
            "Stable period Accuracy: 0.5342\n",
            "Stable period F1 Score: 0.4889\n",
            "Trade War period Accuracy: 0.5204\n",
            "Trade War period F1 Score: 0.4986\n",
            "COVID period Accuracy: 0.5331\n",
            "COVID period F1 Score: 0.5239\n",
            "Ukraine period Accuracy: 0.4909\n",
            "Ukraine period F1 Score: 0.4756\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier\n",
        "\n",
        "classifiers = {\n",
        "    \"LogisticRegression\": LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"label_class\"),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"label_class\"),\n",
        "    \"GBTClassifier\": GBTClassifier(featuresCol=\"scaled_features\", labelCol=\"label_class\"),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(featuresCol=\"scaled_features\", labelCol=\"label_class\"),\n",
        "}\n",
        "\n",
        "for name, model in classifiers.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    clf_model = model.fit(train_period_class_scaled)\n",
        "\n",
        "    # Evaluate on stable period\n",
        "    preds = clf_model.transform(stable_period_class_scaled)\n",
        "    cls_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_class\", metricName=\"accuracy\")\n",
        "    stable_accuracy = cls_eval.evaluate(preds)\n",
        "    stable_f1 = cls_eval.setMetricName(\"f1\").evaluate(preds)\n",
        "    print(f\"Stable period Accuracy: {stable_accuracy:.4f}\")\n",
        "    print(f\"Stable period F1 Score: {stable_f1:.4f}\")\n",
        "\n",
        "    # Evaluate on trade war period\n",
        "    preds = clf_model.transform(trade_war_period_class_scaled)\n",
        "    cls_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_class\", metricName=\"accuracy\")\n",
        "    trade_war_accuracy = cls_eval.evaluate(preds)\n",
        "    trade_war_f1 = cls_eval.setMetricName(\"f1\").evaluate(preds)\n",
        "    print(f\"Trade War period Accuracy: {trade_war_accuracy:.4f}\")\n",
        "    print(f\"Trade War period F1 Score: {trade_war_f1:.4f}\")\n",
        "\n",
        "    # Evaluate on COVID period\n",
        "    preds = clf_model.transform(covid_period_class_scaled)\n",
        "    cls_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_class\", metricName=\"accuracy\")\n",
        "    covid_accuracy = cls_eval.evaluate(preds)\n",
        "    covid_f1 = cls_eval.setMetricName(\"f1\").evaluate(preds)\n",
        "    print(f\"COVID period Accuracy: {covid_accuracy:.4f}\")\n",
        "    print(f\"COVID period F1 Score: {covid_f1:.4f}\")\n",
        "\n",
        "    # Evaluate on Ukraine period\n",
        "    preds = clf_model.transform(ukraine_period_class_scaled)\n",
        "    cls_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_class\", metricName=\"accuracy\")\n",
        "    ukraine_accuracy = cls_eval.evaluate(preds)\n",
        "    ukraine_f1 = cls_eval.setMetricName(\"f1\").evaluate(preds)\n",
        "    print(f\"Ukraine period Accuracy: {ukraine_accuracy:.4f}\")\n",
        "    print(f\"Ukraine period F1 Score: {ukraine_f1:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NON-SCALED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training LogisticRegression...\n",
            "Stable period Accuracy: 0.5388\n",
            "Stable period F1 Score: 0.4143\n",
            "Trade War period Accuracy: 0.5337\n",
            "Trade War period F1 Score: 0.4326\n",
            "COVID period Accuracy: 0.5393\n",
            "COVID period F1 Score: 0.4820\n",
            "Ukraine period Accuracy: 0.4969\n",
            "Ukraine period F1 Score: 0.4324\n",
            "\n",
            "Training RandomForestClassifier...\n",
            "Stable period Accuracy: 0.5335\n",
            "Stable period F1 Score: 0.4891\n",
            "Trade War period Accuracy: 0.5214\n",
            "Trade War period F1 Score: 0.4863\n",
            "COVID period Accuracy: 0.5426\n",
            "COVID period F1 Score: 0.5205\n",
            "Ukraine period Accuracy: 0.4908\n",
            "Ukraine period F1 Score: 0.4677\n",
            "\n",
            "Training GBTClassifier...\n",
            "Stable period Accuracy: 0.5212\n",
            "Stable period F1 Score: 0.4988\n",
            "Trade War period Accuracy: 0.5150\n",
            "Trade War period F1 Score: 0.4938\n",
            "COVID period Accuracy: 0.5327\n",
            "COVID period F1 Score: 0.5173\n",
            "Ukraine period Accuracy: 0.4988\n",
            "Ukraine period F1 Score: 0.4804\n",
            "\n",
            "Training DecisionTreeClassifier...\n",
            "Stable period Accuracy: 0.5342\n",
            "Stable period F1 Score: 0.4873\n",
            "Trade War period Accuracy: 0.5203\n",
            "Trade War period F1 Score: 0.4973\n",
            "COVID period Accuracy: 0.5343\n",
            "COVID period F1 Score: 0.5244\n",
            "Ukraine period Accuracy: 0.4905\n",
            "Ukraine period F1 Score: 0.4744\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier\n",
        "\n",
        "classifiers = {\n",
        "    \"LogisticRegression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label_class\"),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label_class\"),\n",
        "    \"GBTClassifier\": GBTClassifier(featuresCol=\"features\", labelCol=\"label_class\"),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label_class\"),\n",
        "}\n",
        "\n",
        "for name, model in classifiers.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    clf_model = model.fit(train_period_class)\n",
        "\n",
        "    # Evaluate on stable period\n",
        "    preds = clf_model.transform(stable_period_class)\n",
        "    cls_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_class\", metricName=\"accuracy\")\n",
        "    stable_accuracy = cls_eval.evaluate(preds)\n",
        "    stable_f1 = cls_eval.setMetricName(\"f1\").evaluate(preds)\n",
        "    print(f\"Stable period Accuracy: {stable_accuracy:.4f}\")\n",
        "    print(f\"Stable period F1 Score: {stable_f1:.4f}\")\n",
        "\n",
        "    # Evaluate on trade war period\n",
        "    preds = clf_model.transform(trade_war_period_class)\n",
        "    cls_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_class\", metricName=\"accuracy\")\n",
        "    trade_war_accuracy = cls_eval.evaluate(preds)\n",
        "    trade_war_f1 = cls_eval.setMetricName(\"f1\").evaluate(preds)\n",
        "    print(f\"Trade War period Accuracy: {trade_war_accuracy:.4f}\")\n",
        "    print(f\"Trade War period F1 Score: {trade_war_f1:.4f}\")\n",
        "\n",
        "    # Evaluate on COVID period\n",
        "    preds = clf_model.transform(covid_period_class)\n",
        "    cls_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_class\", metricName=\"accuracy\")\n",
        "    covid_accuracy = cls_eval.evaluate(preds)\n",
        "    covid_f1 = cls_eval.setMetricName(\"f1\").evaluate(preds)\n",
        "    print(f\"COVID period Accuracy: {covid_accuracy:.4f}\")\n",
        "    print(f\"COVID period F1 Score: {covid_f1:.4f}\")\n",
        "\n",
        "    # Evaluate on Ukraine period\n",
        "    preds = clf_model.transform(ukraine_period_class)\n",
        "    cls_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_class\", metricName=\"accuracy\")\n",
        "    ukraine_accuracy = cls_eval.evaluate(preds)\n",
        "    ukraine_f1 = cls_eval.setMetricName(\"f1\").evaluate(preds)\n",
        "    print(f\"Ukraine period Accuracy: {ukraine_accuracy:.4f}\")\n",
        "    print(f\"Ukraine period F1 Score: {ukraine_f1:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression in 4 Ways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SCALED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training LinearRegression...\n",
            "Stable period RMSE: 0.016305635365069977\n",
            "Stable period R2: -0.003796823640024538\n",
            "Trade War period RMSE: 0.021225160315171663\n",
            "Trade War period R2: -0.0041997473032719945\n",
            "COVID period RMSE: 0.03749525499501932\n",
            "COVID period R2: 0.009342365932368701\n",
            "Ukraine period RMSE: 0.03149410225567793\n",
            "Ukraine period R2: -0.003026647703651353\n",
            "\n",
            "Training GBTRegressor...\n",
            "Stable period RMSE: 0.016909762135287557\n",
            "Stable period R2: -0.07955646317310894\n",
            "Trade War period RMSE: 0.021240768840201284\n",
            "Trade War period R2: -0.00567722401927373\n",
            "COVID period RMSE: 0.03775366868664583\n",
            "COVID period R2: -0.004359722950431744\n",
            "Ukraine period RMSE: 0.03147866397766223\n",
            "Ukraine period R2: -0.002043529735952454\n",
            "\n",
            "Training RandomForestRegressor...\n",
            "Stable period RMSE: 0.01631624076800345\n",
            "Stable period R2: -0.005103013994769645\n",
            "Trade War period RMSE: 0.021185528944662343\n",
            "Trade War period R2: -0.00045318834625063253\n",
            "COVID period RMSE: 0.03767425098725071\n",
            "COVID period R2: -0.00013867389252930629\n",
            "Ukraine period RMSE: 0.031465652134838026\n",
            "Ukraine period R2: -0.0012153028344124017\n",
            "\n",
            "Training DecisionTreeRegressor...\n",
            "Stable period RMSE: 0.017085603735513058\n",
            "Stable period R2: -0.10212543173849786\n",
            "Trade War period RMSE: 0.02125849612557251\n",
            "Trade War period R2: -0.00735657628382369\n",
            "COVID period RMSE: 0.037751047597532617\n",
            "COVID period R2: -0.004220270280293814\n",
            "Ukraine period RMSE: 0.03147348511890993\n",
            "Ukraine period R2: -0.0017138451581535374\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import LinearRegression, GBTRegressor, RandomForestRegressor, DecisionTreeRegressor\n",
        "\n",
        "regressors = {\n",
        "    \"LinearRegression\": LinearRegression(featuresCol=\"scaled_features\", labelCol=\"label_regress\"),\n",
        "    \"GBTRegressor\": GBTRegressor(featuresCol=\"scaled_features\", labelCol=\"label_regress\"),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=\"label_regress\"),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(featuresCol=\"scaled_features\", labelCol=\"label_regress\")\n",
        "}\n",
        "\n",
        "for name, model in regressors.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    reg_model = model.fit(train_period_regress_scaled)\n",
        "\n",
        "    # Evaluate on stable period\n",
        "    preds = reg_model.transform(stable_period_regress_scaled)\n",
        "    reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label_regress\", metricName=\"rmse\")\n",
        "    stable_rmse = reg_eval.evaluate(preds)\n",
        "    stable_r2 = reg_eval.setMetricName(\"r2\").evaluate(preds)\n",
        "    print(f\"Stable period RMSE: {stable_rmse}\")\n",
        "    print(f\"Stable period R2: {stable_r2}\")\n",
        "\n",
        "    # Evaluate on trade war period\n",
        "    preds = reg_model.transform(trade_war_period_regress_scaled)\n",
        "    reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label_regress\", metricName=\"rmse\")\n",
        "    trade_war_rmse = reg_eval.evaluate(preds)\n",
        "    trade_war_r2 = reg_eval.setMetricName(\"r2\").evaluate(preds)\n",
        "    print(f\"Trade War period RMSE: {trade_war_rmse}\")\n",
        "    print(f\"Trade War period R2: {trade_war_r2}\")\n",
        "\n",
        "    # Evaluate on COVID period\n",
        "    preds = reg_model.transform(covid_period_regress_scaled)\n",
        "    reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label_regress\", metricName=\"rmse\")\n",
        "    covid_rmse = reg_eval.evaluate(preds)\n",
        "    covid_r2 = reg_eval.setMetricName(\"r2\").evaluate(preds)\n",
        "    print(f\"COVID period RMSE: {covid_rmse}\")\n",
        "    print(f\"COVID period R2: {covid_r2}\")\n",
        "\n",
        "\n",
        "    # Evaluate on Ukraine period\n",
        "    preds = reg_model.transform(ukraine_period_regress_scaled)\n",
        "    reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label_regress\", metricName=\"rmse\")\n",
        "    ukraine_rmse = reg_eval.evaluate(preds)\n",
        "    ukraine_r2 = reg_eval.setMetricName(\"r2\").evaluate(preds)\n",
        "    print(f\"Ukraine period RMSE: {ukraine_rmse}\")\n",
        "    print(f\"Ukraine period R2: {ukraine_r2}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NON-SCALED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training LinearRegression...\n",
            "Stable period RMSE: 0.016305635365085842\n",
            "Stable period R2: -0.0037968236419778645\n",
            "Trade War period RMSE: 0.021225160315190048\n",
            "Trade War period R2: -0.004199747305011492\n",
            "COVID period RMSE: 0.03749525499524335\n",
            "COVID period R2: 0.009342365920530726\n",
            "Ukraine period RMSE: 0.03149410225567299\n",
            "Ukraine period R2: -0.0030266477033362715\n",
            "\n",
            "Training GBTRegressor...\n",
            "Stable period RMSE: 0.016482643545111985\n",
            "Stable period R2: -0.025708838926584265\n",
            "Trade War period RMSE: 0.021437545714302113\n",
            "Trade War period R2: -0.024396949113624444\n",
            "COVID period RMSE: 0.037800707565974215\n",
            "COVID period R2: -0.006864029899543489\n",
            "Ukraine period RMSE: 0.03163402047625961\n",
            "Ukraine period R2: -0.01195869785363235\n",
            "\n",
            "Training RandomForestRegressor...\n",
            "Stable period RMSE: 0.016329918752623743\n",
            "Stable period R2: -0.006788885903619812\n",
            "Trade War period RMSE: 0.021183716409454496\n",
            "Trade War period R2: -0.000282007436749776\n",
            "COVID period RMSE: 0.037706048901469835\n",
            "COVID period R2: -0.0018276653847977276\n",
            "Ukraine period RMSE: 0.031464246650913984\n",
            "Ukraine period R2: -0.0011258617779283941\n",
            "\n",
            "Training DecisionTreeRegressor...\n",
            "Stable period RMSE: 0.016287454904528535\n",
            "Stable period R2: -0.0015596443794465564\n",
            "Trade War period RMSE: 0.021236995972509883\n",
            "Trade War period R2: -0.005319991175487981\n",
            "COVID period RMSE: 0.03775619744342185\n",
            "COVID period R2: -0.004494272338671834\n",
            "Ukraine period RMSE: 0.03164979378419643\n",
            "Ukraine period R2: -0.012968112109460916\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import LinearRegression, GBTRegressor, RandomForestRegressor, DecisionTreeRegressor\n",
        "\n",
        "regressors = {\n",
        "    \"LinearRegression\": LinearRegression(featuresCol=\"features\", labelCol=\"label_regress\"),\n",
        "    \"GBTRegressor\": GBTRegressor(featuresCol=\"features\", labelCol=\"label_regress\"),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(featuresCol=\"features\", labelCol=\"label_regress\"),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label_regress\")\n",
        "}\n",
        "\n",
        "for name, model in regressors.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    reg_model = model.fit(train_period_regress)\n",
        "\n",
        "    # Evaluate on stable period\n",
        "    preds = reg_model.transform(stable_period_regress)\n",
        "    reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label_regress\", metricName=\"rmse\")\n",
        "    stable_rmse = reg_eval.evaluate(preds)\n",
        "    stable_r2 = reg_eval.setMetricName(\"r2\").evaluate(preds)\n",
        "    print(f\"Stable period RMSE: {stable_rmse}\")\n",
        "    print(f\"Stable period R2: {stable_r2}\")\n",
        "\n",
        "    # Evaluate on trade war period\n",
        "    preds = reg_model.transform(trade_war_period_regress)\n",
        "    reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label_regress\", metricName=\"rmse\")\n",
        "    trade_war_rmse = reg_eval.evaluate(preds)\n",
        "    trade_war_r2 = reg_eval.setMetricName(\"r2\").evaluate(preds)\n",
        "    print(f\"Trade War period RMSE: {trade_war_rmse}\")\n",
        "    print(f\"Trade War period R2: {trade_war_r2}\")\n",
        "\n",
        "    # Evaluate on COVID period\n",
        "    preds = reg_model.transform(covid_period_regress)\n",
        "    reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label_regress\", metricName=\"rmse\")\n",
        "    covid_rmse = reg_eval.evaluate(preds)\n",
        "    covid_r2 = reg_eval.setMetricName(\"r2\").evaluate(preds)\n",
        "    print(f\"COVID period RMSE: {covid_rmse}\")\n",
        "    print(f\"COVID period R2: {covid_r2}\")\n",
        "\n",
        "    # Evaluate on Ukraine period\n",
        "    preds = reg_model.transform(ukraine_period_regress)\n",
        "    reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label_regress\", metricName=\"rmse\")\n",
        "    ukraine_rmse = reg_eval.evaluate(preds)\n",
        "    ukraine_r2 = reg_eval.setMetricName(\"r2\").evaluate(preds)\n",
        "    print(f\"Ukraine period RMSE: {ukraine_rmse}\")\n",
        "    print(f\"Ukraine period R2: {ukraine_r2}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "BDPA",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
